{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf060be",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Processamento de Linguagem Natural\n",
    " - Comunicação Homem-Máquina\n",
    "     - input natural --[NLP]--> output natural\n",
    "     \n",
    "## Corretor Ortográfico\n",
    "**INPUT -> ALGORITMO -> OUTPUT**\n",
    "Algoritmo:\n",
    "- Criar Vocabulário [DATABASE]\n",
    "*CORPUS* -> Base de dados, corpo com diversos textos, conjunto de documentos\n",
    "documentos -> Elementos do *Corpus*\n",
    "Token -> Elementos do vetor, separar a string em elementos diferentes (estes elementos são os tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bc0dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Documentations:\n",
    "[Natural Language Toolkit (NLTK)](nltk.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d25e990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10e7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/artigos.txt', 'r', encoding=\"utf8\") as f: #f = file\n",
    "    artigos=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0e294a-9fe5-4b43-83b7-7c5f9198aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlkt.download('punkt') # to use tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6116f0-a939-41b2-8191-bab315b04280",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Limpando os dados:\n",
    "- Retirar pontuações;\n",
    "- Limpar palavras com letras maiúsculas;\n",
    "- Limpar palavras repetidas.\n",
    "**BONUS:**\n",
    "- sorting values para facilitar o algoritmo de pesquisa por meio de pesquisa binária;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec979d58",
   "metadata": {},
   "source": [
    "**Este Corpus é interessante para o NLP?**\n",
    "- Ele tem palavras o suficiente?\n",
    "- Ele tem muitas palavras repetidas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a23607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retirar pontuações\n",
    "\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_retorno=[]\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_retorno.append(token)\n",
    "    return lista_retorno\n",
    "\n",
    "#import sys\n",
    "#sys.setrecursionlimit(len(lista_tokens))\n",
    "def retira_pontuacoes(lista_tokens:list, lista_retorno:list=[], index:int=0):\n",
    "    \"\"\"Função recursiva para retirar pontuações, checa se ainda estamos dentro da lista, caso sim,\n",
    "    checa se a palavra no índice index possui apenas conjuntos alpha, se sim, adicionamos esta palavra à\n",
    "    lista de retorno lista_retorno, retornamos à função atualizando a lista de retorno e índice.\n",
    "    caso o índice seja maior que o \"tamanho da lista de tokens - 1\", retornamos lista final.\n",
    "    \"\"\"\n",
    "    if index < len(lista_tokens):\n",
    "        if lista_tokens[index].isalpha(): \n",
    "            lista_retorno.append(lista_tokens[index])\n",
    "        return retira_pontuacoes(lista_tokens, lista_retorno, (index+1))\n",
    "    return lista_retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca376f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descobrir quantidade de PALAVRAS [sem pontuação]\n",
    "\n",
    "lista_tokens=nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras= separa_palavras(lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386e1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras dentro da lista não tratada é: 515827\n",
      "O número de palavras dentro da lista tratada é: 403031\n"
     ]
    }
   ],
   "source": [
    "print(\"O número de palavras dentro da lista não tratada é: {}\".format(len(lista_tokens))) # Número de tokens NÃO tratados dentro da lista [PONTUAÇÕES]\n",
    "print(\"O número de palavras dentro da lista tratada é: {}\".format(len(lista_palavras))) # Número de tokens tratados dentro da lista [PONTUAÇÕES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f6fd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantidade de palavras repetidas\n",
    "# Cuidar letras maiusculas! Passar tudo .lower()\n",
    "\n",
    "def tratar_repeticoes(lista_tokens):\n",
    "    lista_retorno=[]\n",
    "    for token in lista_tokens:\n",
    "        if token.lower() not in lista_retorno:\n",
    "            lista_retorno.append(token.lower())\n",
    "    return lista_retorno\n",
    "\n",
    "# tokens_tratados=tratar_repeticoes(lista_palavras)\n",
    "\n",
    "# Outra função interessante:\n",
    "def tratar_normalizacao(lista_tokens):\n",
    "    # Transforma todas as palavras da lista em minusculo\n",
    "    lista_retorno=[]\n",
    "    for token in lista_tokens:\n",
    "        lista_retorno.append(token.lower())\n",
    "    return lista_retorno\n",
    "\n",
    "tokens_tratados3=tratar_normalizacao(lista_palavras)\n",
    "tokens_tratados= set(tratar_normalizacao(lista_palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d0e202b-2612-4724-bb99-fbf17b452367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listas de palavras sem repetições, em minusculo:\n",
      "18464\n",
      "Listas de palavras com repetições, em minusculo:\n",
      "403031\n"
     ]
    }
   ],
   "source": [
    "print('Listas de palavras sem repetições, em minusculo:')\n",
    "print(len(tokens_tratados))\n",
    "print('Listas de palavras com repetições, em minusculo:')\n",
    "print(len(tokens_tratados3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa30ac-ec33-4b98-8c4b-4baa57c49bfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Desenvolvendo o Corretor\n",
    "DB = tokens_tratados3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c58b61-395a-4b1b-b3bf-a21510074826",
   "metadata": {},
   "source": [
    "### Letras => Operação (inserção) => Retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499c07f-60ee-446f-bfb2-40231da630e8",
   "metadata": {},
   "source": [
    "# GERADOR DE PALAVRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fcdcf541-c965-4970-8779-144ccfe23fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example='eme'\n",
    "\n",
    "def gerador_palavras(palavra:str):\n",
    "    fatias= []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "        palavras_geradas=insere_letras(fatias)\n",
    "        \n",
    "        palavras_geradas_D= deleta_letras(fatias)\n",
    "        \n",
    "        palavras_geradas_S= substitui_letras(fatias)\n",
    "        for element in palavras_geradas_D:\n",
    "            palavras_geradas.append(element)\n",
    "        for element in palavras_geradas_S:\n",
    "            palavras_geradas.append(element)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abeb493-deb2-4794-93f2-da74152cac02",
   "metadata": {
    "tags": []
   },
   "source": [
    "# INSERÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "37e2baf2-cab7-49c6-8695-b375c6700590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias:list):\n",
    "    novas_palavras=[]\n",
    "    letras= 'abcdefghijklmnopqrstuvwxyzáàâãéèêẽiíìĩîóòõôùúũûç'\n",
    "    for L, R in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(L + letra + R)\n",
    "    return novas_palavras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e4b90-b91a-4f8e-900d-c7b936d1c393",
   "metadata": {},
   "source": [
    "# DELEÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5cca6f36-b267-4eab-b274-3c4b3c9302ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleta_letras(fatias:list):\n",
    "    novas_palavras=[]\n",
    "    for L, R in fatias:\n",
    "            novas_palavras.append(L+ R[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272eb6a9-4e06-4e9f-9c06-0718aa19b187",
   "metadata": {},
   "source": [
    "# SUBSTITUIÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "87c9c623-c28e-4f6e-9751-5013842d3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitui_letras(fatias:list):\n",
    "    novas_palavras=[]\n",
    "    letras= 'abcdefghijklmnopqrstuvwxyzáàâãéèêẽiíìĩîóòõôùúũûç'\n",
    "    for L, R in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(L+ letra + R[1:])\n",
    "    return(novas_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9105afa-f2e9-4ad5-be3f-63b73bcbf25a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ALGORITMO CORRETOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9ee226f9-98ce-451c-ae61-aaf4f73ec6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas=gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "frequencia = nltk.FreqDist(tokens_tratados3) # LISTA COM REPETIÇÕES\n",
    "\n",
    "def probabilidade(palavra_gerada):\n",
    "    \"\"\"frequencia_palavra/total_de_palavras\"\"\"\n",
    "    prob = frequencia[palavra_gerada]/len(tokens_tratados3)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "10eb1472-3a36-4e82-9361-04963999ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'em'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1ba77-e4a7-478e-9358-d26ee7e12d77",
   "metadata": {},
   "source": [
    "# FUNÇÃO DE TESTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2de24cc0-e8a8-47e2-a164-79da1e78f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_dados_teste=[]\n",
    "    #ler arquivo\n",
    "    f = open(nome_arquivo, 'r')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split() #Separar as palavras\n",
    "        lista_dados_teste.append((correta, errada)) #append ((correta, errada), (correta1, errada1))\n",
    "    f.close()\n",
    "    return lista_dados_teste\n",
    "\n",
    "def test(testes):\n",
    "    acertou=0\n",
    "    for correta, errada in testes:\n",
    "        corrigida= corretor(errada)\n",
    "        if corrigida == correta:\n",
    "            acertou+=1\n",
    "            #print('CERTO! INPUT: {} -> OUTPUT: {} -> RIGHT: {}'.format(errada, corrigida, correta))\n",
    "        else:\n",
    "            print('ERRADO! INPUT: {} -> OUTPUT: {} -> RIGHT: {}'.format(errada, corrigida, correta))\n",
    "    taxa_acerto= float(acertou/len(testes))\n",
    "    print('taxa de acerto: {}%'.format(round((taxa_acerto*100) ,4)))# de {} palavras'.format(round((taxa_acerto*100), 4), len(testes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2489d552-5581-4dee-864e-fbba6e488bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERRADO! INPUT: eme -> OUTPUT: em -> RIGHT: ele\n",
      "ERRADO! INPUT: noâ -> OUTPUT: no -> RIGHT: nos\n",
      "ERRADO! INPUT: teb -> OUTPUT: tem -> RIGHT: ter\n",
      "ERRADO! INPUT: âem -> OUTPUT: em -> RIGHT: bem\n",
      "ERRADO! INPUT: serr -> OUTPUT: ser -> RIGHT: será\n",
      "ERRADO! INPUT: eû -> OUTPUT: e -> RIGHT: eu\n",
      "ERRADO! INPUT: jé -> OUTPUT: é -> RIGHT: já\n",
      "ERRADO! INPUT: dms -> OUTPUT: dos -> RIGHT: das\n",
      "ERRADO! INPUT: cava -> OUTPUT: java -> RIGHT: cada\n",
      "ERRADO! INPUT: nossk -> OUTPUT: nosso -> RIGHT: nossa\n",
      "ERRADO! INPUT: ìeu -> OUTPUT: seu -> RIGHT: eu\n",
      "ERRADO! INPUT: qelay -> OUTPUT: delay -> RIGHT: ela\n",
      "ERRADO! INPUT: dtilizacr -> OUTPUT: adtilizacr -> RIGHT: utilizar\n",
      "ERRADO! INPUT: bprojõto -> OUTPUT: abprojõto -> RIGHT: projeto\n",
      "ERRADO! INPUT: ysiteo -> OUTPUT: aysiteo -> RIGHT: site\n",
      "ERRADO! INPUT: sõêm -> OUTPUT: asõêm -> RIGHT: sem\n",
      "ERRADO! INPUT: peàli -> OUTPUT: apeàli -> RIGHT: pelo\n",
      "ERRADO! INPUT: asuraó -> OUTPUT: aasuraó -> RIGHT: alura\n",
      "ERRADO! INPUT: deiìa -> OUTPUT: deixa -> RIGHT: dia\n",
      "ERRADO! INPUT: tuĩdoì -> OUTPUT: atuĩdoì -> RIGHT: tudo\n",
      "ERRADO! INPUT: eúaa -> OUTPUT: aeúaa -> RIGHT: ela\n",
      "ERRADO! INPUT: utilizẽaçr -> OUTPUT: autilizẽaçr -> RIGHT: utilizar\n",
      "ERRADO! INPUT: prêjetó -> OUTPUT: aprêjetó -> RIGHT: projeto\n",
      "ERRADO! INPUT: sqiqte -> OUTPUT: asqiqte -> RIGHT: site\n",
      "ERRADO! INPUT: sũexm -> OUTPUT: asũexm -> RIGHT: sem\n",
      "ERRADO! INPUT: pçlxo -> OUTPUT: apçlxo -> RIGHT: pelo\n",
      "ERRADO! INPUT: uluraa -> OUTPUT: auluraa -> RIGHT: alura\n",
      "ERRADO! INPUT: dĩaz -> OUTPUT: adĩaz -> RIGHT: dia\n",
      "ERRADO! INPUT: kzudo -> OUTPUT: akzudo -> RIGHT: tudo\n",
      "ERRADO! INPUT: ewpoderamento -> OUTPUT: aewpoderamento -> RIGHT: empoderamento\n",
      "ERRADO! INPUT: cakvalo -> OUTPUT: acakvalo -> RIGHT: cavalo\n",
      "ERRADO! INPUT: canelac -> OUTPUT: acanelac -> RIGHT: canela\n",
      "ERRADO! INPUT: tênisy -> OUTPUT: atênisy -> RIGHT: tênis\n",
      "ERRADO! INPUT: anciosa -> OUTPUT: aanciosa -> RIGHT: ansiosa\n",
      "ERRADO! INPUT: ancciosa -> OUTPUT: aancciosa -> RIGHT: ansiosa\n",
      "ERRADO! INPUT: ansioa -> OUTPUT: aansioa -> RIGHT: ansiosa\n",
      "ERRADO! INPUT: empoderamento -> OUTPUT: aempoderamento -> RIGHT: empoderamento\n",
      "ERRADO! INPUT: asterístico -> OUTPUT: aasterístico -> RIGHT: asterisco\n",
      "ERRADO! INPUT: entertido -> OUTPUT: aentertido -> RIGHT: entretido\n",
      "ERRADO! INPUT: indiota -> OUTPUT: aindiota -> RIGHT: idiota\n",
      "ERRADO! INPUT: tomare -> OUTPUT: tomar -> RIGHT: tomara\n",
      "ERRADO! INPUT: provalecer -> OUTPUT: aprovalecer -> RIGHT: prevalecer\n",
      "ERRADO! INPUT: mindigo -> OUTPUT: amindigo -> RIGHT: mendigo\n",
      "ERRADO! INPUT: pertubar -> OUTPUT: apertubar -> RIGHT: perturbar\n",
      "taxa de acerto: 76.3441%\n"
     ]
    }
   ],
   "source": [
    "test_data=cria_dados_teste('./data/test_data.txt')\n",
    "test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86299b51-e462-401f-ad73-401d81895852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTRA FORMA DE PENSAR:\n",
    "## QUAIS PALAVRAS POSSUEM ESTAS LETRAS?\n",
    "## CHECAR PROBABILIDADE DAS PALAVRAS\n",
    "## RETORNAR A PALAVRA COM MAIOR PROBABILIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad295930-4537-41b9-b55e-068c5869bdff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
